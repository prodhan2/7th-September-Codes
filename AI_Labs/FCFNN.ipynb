{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e18232",
   "metadata": {},
   "source": [
    "![Chart Image](chart.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9e64eb",
   "metadata": {},
   "source": [
    "কিভাবে TensorFlow.Keras দিয়ে একটি Fully Connected Feed-forward Neural Network ডিজাইন ও ইমপ্লিমেন্ট করতে হয়?\n",
    "\n",
    "\"আমার 3টা input, hidden layer 2টা, each 4টা neuron এবং output layer 3টা neuron হবে\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8edbf44",
   "metadata": {},
   "source": [
    "| ধাপ | কাজ               | উদাহরণ                                                             |\n",
    "| --- | ----------------- | ------------------------------------------------------------------ |\n",
    "| ১   | লাইব্রেরি ইমপোর্ট | `from tensorflow.keras.layers import Input, Dense`                 |\n",
    "| ২   | ডেটা প্রস্তুতি    | `X` ও `y` numpy অ্যারে তৈরি করা                                    |\n",
    "| ৩   | মডেল ডিজাইন       | ইনপুট (3), হিডেন (4,4), আউটপুট (3)                                 |\n",
    "| ৪   | মডেল তৈরি         | `model = Model(inputs, outputs)`                                   |\n",
    "| ৫   | কম্পাইল           | `model.compile(optimizer='adam', loss='categorical_crossentropy')` |\n",
    "| ৬   | ট্রেইন            | `model.fit(X, y, epochs=100)`                                      |\n",
    "| ৭   | প্রেডিকশন         | `model.predict(X_new)`                                             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7166474b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4667 - loss: 1.0633  \n",
      "Epoch 2/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3347 - loss: 1.1120     \n",
      "Epoch 3/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4458 - loss: 1.0762 \n",
      "Epoch 4/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4667 - loss: 1.0679 \n",
      "Epoch 5/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2028 - loss: 1.1520     \n",
      "Epoch 6/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3486 - loss: 1.0704 \n",
      "Epoch 7/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4181 - loss: 1.0525 \n",
      "Epoch 8/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3625 - loss: 1.0908     \n",
      "Epoch 9/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3139 - loss: 1.1362     \n",
      "Epoch 10/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3486 - loss: 1.0789  \n",
      "Epoch 11/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3486 - loss: 1.0792 \n",
      "Epoch 12/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4458 - loss: 1.0523 \n",
      "Epoch 13/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4181 - loss: 1.0713 \n",
      "Epoch 14/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5361 - loss: 1.0639 \n",
      "Epoch 15/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5500 - loss: 1.0322 \n",
      "Epoch 16/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4181 - loss: 1.0838 \n",
      "Epoch 17/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4458 - loss: 1.0542 \n",
      "Epoch 18/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3208 - loss: 1.0615     \n",
      "Epoch 19/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5083 - loss: 1.0621 \n",
      "Epoch 20/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2931 - loss: 1.1278     \n",
      "Epoch 21/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2722 - loss: 1.1300     \n",
      "Epoch 22/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2236 - loss: 1.1367     \n",
      "Epoch 23/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3139 - loss: 1.0695     \n",
      "Epoch 24/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3972 - loss: 1.0533 \n",
      "Epoch 25/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2653 - loss: 1.1277     \n",
      "Epoch 26/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4875 - loss: 1.0271 \n",
      "Epoch 27/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5708 - loss: 1.0349 \n",
      "Epoch 28/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4667 - loss: 1.0638 \n",
      "Epoch 29/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2931 - loss: 1.1025     \n",
      "Epoch 30/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2653 - loss: 1.1077     \n",
      "Epoch 31/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5014 - loss: 1.0496 \n",
      "Epoch 32/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4875 - loss: 1.0367 \n",
      "Epoch 33/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5917 - loss: 1.0377 \n",
      "Epoch 34/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5708 - loss: 1.0392 \n",
      "Epoch 35/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2514 - loss: 1.1190     \n",
      "Epoch 36/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2931 - loss: 1.0863     \n",
      "Epoch 37/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2236 - loss: 1.1153     \n",
      "Epoch 38/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5917 - loss: 1.0195 \n",
      "Epoch 39/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1750 - loss: 1.1283     \n",
      "Epoch 40/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3486 - loss: 1.0697 \n",
      "Epoch 41/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4458 - loss: 1.0429 \n",
      "Epoch 42/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3972 - loss: 1.0587 \n",
      "Epoch 43/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4458 - loss: 1.0401 \n",
      "Epoch 44/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2236 - loss: 1.1335     \n",
      "Epoch 45/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4375 - loss: 1.1090     \n",
      "Epoch 46/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4792 - loss: 1.0959 \n",
      "Epoch 47/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4306 - loss: 1.0909 \n",
      "Epoch 48/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5208 - loss: 1.0905 \n",
      "Epoch 49/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5278 - loss: 1.0643 \n",
      "Epoch 50/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4583 - loss: 1.0904 \n",
      "Epoch 51/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5000 - loss: 1.0391 \n",
      "Epoch 52/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3264 - loss: 1.1095     \n",
      "Epoch 53/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4722 - loss: 1.0919 \n",
      "Epoch 54/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4722 - loss: 1.0741 \n",
      "Epoch 55/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5833 - loss: 1.0384 \n",
      "Epoch 56/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5278 - loss: 1.0685 \n",
      "Epoch 57/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6458 - loss: 1.0322 \n",
      "Epoch 58/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3750 - loss: 1.0763     \n",
      "Epoch 59/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6042 - loss: 1.0467 \n",
      "Epoch 60/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3681 - loss: 1.0980     \n",
      "Epoch 61/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5208 - loss: 1.0513 \n",
      "Epoch 62/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4167 - loss: 1.0976     \n",
      "Epoch 63/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5556 - loss: 1.0269 \n",
      "Epoch 64/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5417 - loss: 1.0589\n",
      "Epoch 65/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4514 - loss: 1.0703 \n",
      "Epoch 66/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4653 - loss: 1.0429     \n",
      "Epoch 67/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5000 - loss: 1.0708 \n",
      "Epoch 68/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3958 - loss: 1.1123     \n",
      "Epoch 69/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5486 - loss: 1.0615 \n",
      "Epoch 70/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4167 - loss: 1.0599     \n",
      "Epoch 71/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5625 - loss: 1.0465 \n",
      "Epoch 72/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4375 - loss: 1.0900     \n",
      "Epoch 73/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4306 - loss: 1.0780 \n",
      "Epoch 74/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4514 - loss: 1.0835 \n",
      "Epoch 75/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5278 - loss: 1.0447 \n",
      "Epoch 76/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6792 - loss: 1.0315 \n",
      "Epoch 77/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4222 - loss: 1.1040     \n",
      "Epoch 78/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4292 - loss: 1.0980     \n",
      "Epoch 79/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6792 - loss: 1.0328 \n",
      "Epoch 80/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5958 - loss: 1.0698 \n",
      "Epoch 81/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5819 - loss: 1.0558 \n",
      "Epoch 82/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6236 - loss: 1.0494 \n",
      "Epoch 83/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5819 - loss: 1.0609 \n",
      "Epoch 84/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6236 - loss: 1.0437 \n",
      "Epoch 85/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6583 - loss: 1.0348 \n",
      "Epoch 86/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 1.0816 \n",
      "Epoch 87/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4083 - loss: 1.0849     \n",
      "Epoch 88/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7556 - loss: 1.0129 \n",
      "Epoch 89/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5611 - loss: 1.0677 \n",
      "Epoch 90/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7347 - loss: 1.0085 \n",
      "Epoch 91/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4917 - loss: 1.0763 \n",
      "Epoch 92/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5819 - loss: 1.0761 \n",
      "Epoch 93/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4986 - loss: 1.0704     \n",
      "Epoch 94/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6236 - loss: 1.0252 \n",
      "Epoch 95/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 1.0604 \n",
      "Epoch 96/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6236 - loss: 1.0306 \n",
      "Epoch 97/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4708 - loss: 1.0815     \n",
      "Epoch 98/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4292 - loss: 1.1050     \n",
      "Epoch 99/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5542 - loss: 1.0806 \n",
      "Epoch 100/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5819 - loss: 1.0543 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "[[0.4164442  0.2902115  0.29334432]\n",
      " [0.3513376  0.26914907 0.37951338]\n",
      " [0.3850599  0.31473917 0.3002009 ]\n",
      " [0.35366148 0.3106249  0.3357137 ]\n",
      " [0.40017274 0.3027938  0.29703352]\n",
      " [0.31092858 0.25357094 0.43550044]\n",
      " [0.37088293 0.26842198 0.3606951 ]\n",
      " [0.39974934 0.30312496 0.2971257 ]\n",
      " [0.33976147 0.2594352  0.4008034 ]\n",
      " [0.41079295 0.2945494  0.29465768]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Input Layer (3 input features)\n",
    "inputs = Input(shape=(3,))\n",
    "\n",
    "# Step 2: Hidden Layers (each with 4 neurons)\n",
    "hidden1 = Dense(4, activation='relu')(inputs)\n",
    "hidden2 = Dense(4, activation='relu')(hidden1)\n",
    "\n",
    "# Step 3: Output Layer (3 neurons for 3 classes with softmax)\n",
    "outputs = Dense(3, activation='softmax')(hidden2)\n",
    "\n",
    "# Step 4: Build Model\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Step 5: Compile Model (Categorical classification)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 6: Dummy Data (10 samples, 3 features)\n",
    "X = np.random.rand(10, 3)  # 10 rows, 3 input features\n",
    "\n",
    "# Labels: 10 samples, 3 classes → one-hot encoded\n",
    "y = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1],\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1],\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1],\n",
    "    [1, 0, 0],\n",
    "])\n",
    "\n",
    "# Step 7: Train the model\n",
    "model.fit(X, y, epochs=100, batch_size=2)\n",
    "\n",
    "# Step 8: Prediction\n",
    "predictions = model.predict(X)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66379f52",
   "metadata": {},
   "source": [
    "\n",
    "এই আউটপুট থেকে কী বুঝবে?\n",
    "১. প্রতিটি ভেক্টরে ৩টি সংখ্যা আছে, যেগুলো হলো ৩টি ক্লাসের সম্ভাবনা (probability)।\n",
    "\n",
    "২. প্রতিটি ভেক্টরের মানগুলোর যোগফল মোটামুটি ১ এর কাছাকাছি।\n",
    "\n",
    "৩. উদাহরণস্বরূপ, প্রথম ভেক্টর:\n",
    "\n",
    "প্রথম স্যাম্পল: ১ম ক্লাস (৩৭.০৯%) সবচেয়ে বেশি\n",
    "\n",
    "দ্বিতীয় স্যাম্পল: ১ম ক্লাস (৩৯.৯৭%) সবচেয়ে বেশি\n",
    "\n",
    "তৃতীয় স্যাম্পল: ৩য় ক্লাস (৪০.০৮%) সবচেয়ে বেশি\n",
    "\n",
    "চতুর্থ স্যাম্পল: ১ম ক্লাস (৪১.০৭%) সবচেয়ে বেশি\n",
    "\n",
    "এখানে প্রথম ক্লাসের সম্ভাবনা সবচেয়ে বেশি, তাই মডেল প্রথম ক্লাসে ইনপুটটা পড়বে বলে অনুমান করছে।\n",
    "\n",
    "কিন্তু এই ক্ষেত্রে…\n",
    "সম্ভাবনাগুলো প্রায় সমান সমান (ক্লাসগুলোর মধ্যে পার্থক্য খুব কম)\n",
    "\n",
    "অর্থাৎ মডেল এখনও নিশ্চিত নয় যে কোন ক্লাস সঠিক — এটি হয়তো ট্রেনিং যথেষ্ট হয়নি বা ডেটা খুব সহজ নয়।\n",
    "\n",
    "সারমর্ম\n",
    "প্রতিটি ইনপুটের জন্য মডেল ৩টি ক্লাসের সম্ভাবনা দেয়।\n",
    "\n",
    "যত ভালো ট্রেনিং হবে, এই সংখ্যাগুলো একটি ক্লাসের দিকে বেশি ঝুঁকবে (যেমন 0.9, 0.05, 0.05)\n",
    "\n",
    "এখন তোমার আউটপুটে ক্লাসের সম্ভাবনা প্রায় কাছাকাছি, তাই মডেল পুরোপুরি শিখতে পারেনি বা ডেটা ও মডেল আরো উন্নত করা দরকার।\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
